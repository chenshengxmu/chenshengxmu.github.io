---
layout: post
title: Apple patents augmented-reality mapping tech
---
![img](http://media.idownloadblog.com/wp-content/uploads/2013/03/Apple-patent-8400548-drawing-001.png)
* Apple Tuesday was granted a patent for technology enabling integrating augmented reality, the power of the Internet and smart device communications. A key component to the company’s take on augmented reality is a system that recognizes live real-world objects, then builds 3D representations useful for mapping and annotating shared data. The patent, filed in 2010, is entitled “Synchronized, interactive augmented reality displays for multifunction devices.”
* In one potential use, an iDevice camera photographs a circuit board. A layer placed over the image then identifies the components and permits a team to exchange annotations, including text, web links and even images. But this only scratches the surface of how Apple envisions the future of mobile augmented reality…
* Apple’s U.S. Patent No. 8,400,548 filing educates us on augmented reality:
* A device can receive live video of a real-world, physical environment on a touch sensitive surface. One or more objects can be identified in the live video. An information layer can be generated related to the objects.
* In some implementations, the information layer can include annotations made by a user through the touch sensitive surface. The information layer and live video can be combined in a display of the device.
* Along with layering data over a live image, Apple’s proposed technology could create a second display created solely by the device.
* One example outlines an iDevice user surveying the San Francisco cityscape. While one windows displays the live scene, another window draws a 3-D interpretation, includes landmarks and then sends it to another user.
![img](http://media.idownloadblog.com/wp-content/uploads/2013/03/Apple-patent-8400548-drawing-002.png)
* Once received, the data is used as a map, allowing the second person to enjoy the same site – and perhaps even meet up with the sender for a coffee.
* Data can be received from one or more onboard sensors indicating that the device is in motion.
* The sensor data can be used to synchronize the live video and the information layer as the perspective of video camera view changes due to the motion.
* The live video and information layer can be shared with other devices over a communication link.
* Apple’s patent comes amid talk of Google’s glass, which combines real-life images with data pulled from the Internet.
* The technology Apple now outlines is not the company’s first foray into augmenting how consumers view the nexis of technology and reality.
* Prior to this, we reported on a series of Apple patents which spanned wearable computing, and how iDevices could be harnessed.

